{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "ROOT_DIR=\"\"\n",
    "DATA_DIR=os.path.join(ROOT_DIR,\"data\") ##Directory of dataset\n",
    "DATASET_FILE=os.path.join(DATA_DIR,\"train_x_lpd_5_phr.npz\")\n",
    "# DATASET_FILE=os.path.join(DATA_DIR,\"Jsb16thSeparated.npz\")\n",
    "EXPERIMENTS_DIR=os.path.join(ROOT_DIR, \"logs/experiments\")\n",
    "use_cuda = torch .cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if use_cuda else \"cpu\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utils"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from time import strftime\n",
    "def setup_logger(args):\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    a_logger = logging.getLogger()\n",
    "    a_logger.setLevel(args.log_level)\n",
    "    log_dir=os.path.join(ROOT_DIR,\"logs\",\"output_logs\")\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    output_file_handler = logging.FileHandler(os.path.join(log_dir,strftime(\"log_%d_%m_%Y_%H_%M.log\")))\n",
    "    stdout_handler = logging.StreamHandler(sys.stdout)\n",
    "    stdout_handler.setFormatter(formatter)\n",
    "    a_logger.propagate=False\n",
    "    a_logger.addHandler(output_file_handler)\n",
    "    a_logger.addHandler(stdout_handler)\n",
    "\n",
    "import json\n",
    "import os\n",
    "from enum import Enum\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "\n",
    "def read_json(path_json):\n",
    "    with open(path_json, encoding='utf8') as json_file:\n",
    "        return json.load(json_file)\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "def chunks(data, SIZE):\n",
    "    \"\"\"Split a dictionnary into parts of max_size =SIZE\"\"\"\n",
    "    it = iter(data)\n",
    "    for _ in range(0, len(data), SIZE):\n",
    "        yield {k: data[k] for k in islice(it, SIZE)}\n",
    "\n",
    "def sorted_dict(x, ascending=True):\n",
    "    \"\"\"\n",
    "    Sort dict according to value.\n",
    "    x must be a primitive type: int,float, str...\n",
    "    @param x:\n",
    "    @return:\n",
    "    \"\"\"\n",
    "    return dict(sorted(x.items(), key=lambda item: (1 if ascending else -1) * item[1]))\n",
    "def reverse_dict(input_dict):\n",
    "    \"\"\"\n",
    "    Reverse a dictonary\n",
    "    Args:\n",
    "        input_dict:\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    inv_dict = {}\n",
    "    for k, v in input_dict.items():\n",
    "        inv_dict[v] = inv_dict.get(v, []) + [k]\n",
    "\n",
    "    return inv_dict\n",
    "\n",
    "def save_matrix(matrix,filename):\n",
    "    with open(filename,'wb') as output:\n",
    "        np.save(output,matrix)\n",
    "def load_matrix(filename,auto_delete=False):\n",
    "    with open(filename,'rb') as input:\n",
    "        matrix=np.load(input)\n",
    "\n",
    "    if auto_delete:\n",
    "        os.remove(filename)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "\n",
    "class Averager:\n",
    "    def __init__(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "\n",
    "    def send(self, value):\n",
    "        self.current_total += value\n",
    "        self.iterations += 1\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        if self.iterations == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1.0 * self.current_total / self.iterations\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "\"\"\"Utils.\"\"\"\n",
    "from typing import List\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "def initialize_weights(layer: nn.Module, mean: float = 0.0, std: float = 0.02):\n",
    "    \"\"\"Initialize module with normal distribution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    layer: nn.Module\n",
    "        Layer.\n",
    "    mean: float, (default=0.0)\n",
    "        Mean value.\n",
    "    std: float, (default=0.02)\n",
    "        Standard deviation value.\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(layer, (nn.Conv3d, nn.ConvTranspose2d)):\n",
    "        torch.nn.init.normal_(layer.weight, mean, std)\n",
    "    elif isinstance(layer, (nn.Linear, nn.BatchNorm2d)):\n",
    "        torch.nn.init.normal_(layer.weight, mean, std)\n",
    "        torch.nn.init.constant_(layer.bias, 0)\n",
    "\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    \"\"\"Reshape layer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    shape: List[int]\n",
    "        Dimensions after number of batches.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, shape: List[int]) -> None:\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Perform forward.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: Tensor\n",
    "            Input batch.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tensor:\n",
    "            Preprocessed input batch.\n",
    "\n",
    "        \"\"\"\n",
    "        return x.view(x.size(0), *self.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "\"\"\"Bar Generator.\"\"\"\n",
    "\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "class BarGenerator(nn.Module):\n",
    "    \"\"\"Bar generator.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    z_dimension: int, (default=32)\n",
    "        Noise space dimension.\n",
    "    hid_channels: int, (default=1024)\n",
    "        Number of hidden channels.\n",
    "    hid_features: int, (default=1024)\n",
    "        Number of hidden features.\n",
    "    out_channels: int, (default=1)\n",
    "        Number of output channels.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        z_dimension: int = 32,\n",
    "        hid_features: int = 1024,\n",
    "        hid_channels: int = 512,\n",
    "        out_channels: int = 1,\n",
    "        n_steps_per_bar = 16,\n",
    "        n_pitches = 84,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super().__init__()\n",
    "        self.n_steps_per_bar = n_steps_per_bar\n",
    "        self.n_pitches = n_pitches\n",
    "        self.net = nn.Sequential(\n",
    "            # input shape: (batch_size, 4*z_dimension)\n",
    "            nn.Linear(4 * z_dimension, hid_features),\n",
    "            nn.BatchNorm1d(hid_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # output shape: (batch_size, hid_features)\n",
    "            Reshape(shape=[hid_channels, hid_features // hid_channels, 1]),\n",
    "            # output shape: (batch_size, hid_channels, hid_features//hid_channels, 1)\n",
    "            nn.ConvTranspose2d(\n",
    "                hid_channels,\n",
    "                hid_channels,\n",
    "                kernel_size=(2, 1),\n",
    "                stride=(2, 1),\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.BatchNorm2d(hid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # output shape: (batch_size, hid_channels, 2*hid_features//hid_channels, 1)\n",
    "            nn.ConvTranspose2d(\n",
    "                hid_channels,\n",
    "                hid_channels // 2,\n",
    "                kernel_size=(2, 1),\n",
    "                stride=(2, 1),\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.BatchNorm2d(hid_channels // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # output shape: (batch_size, hid_channels//2, 4*hid_features//hid_channels, 1)\n",
    "            nn.ConvTranspose2d(\n",
    "                hid_channels // 2,\n",
    "                hid_channels // 2,\n",
    "                kernel_size=(2, 1),\n",
    "                stride=(2, 1),\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.BatchNorm2d(hid_channels // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # output shape: (batch_size, hid_channels//2, 8*hid_features//hid_channels, 1)\n",
    "            nn.ConvTranspose2d(\n",
    "                hid_channels // 2,\n",
    "                hid_channels // 2,\n",
    "                kernel_size=(1, 7),\n",
    "                stride=(1, 7),\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.BatchNorm2d(hid_channels // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # output shape: (batch_size, hid_channels//2, 8*hid_features//hid_channels, 7)\n",
    "            nn.ConvTranspose2d(\n",
    "                hid_channels // 2,\n",
    "                out_channels,\n",
    "                kernel_size=(1, 12),\n",
    "                stride=(1, 12),\n",
    "                padding=0,\n",
    "            ),\n",
    "            # output shape: (batch_size, out_channels, 8*hid_features//hid_channels, n_pitches)\n",
    "            Reshape(shape=[1, 1, self.n_steps_per_bar, self.n_pitches])\n",
    "            # output shape: (batch_size, out_channels, 1, n_steps_per_bar, n_pitches)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Perform forward.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: Tensor\n",
    "            Input batch.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tensor:\n",
    "            Preprocessed input batch.\n",
    "\n",
    "        \"\"\"\n",
    "        fx = self.net(x)\n",
    "        return fx\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "\"\"\"Temporal Network.\"\"\"\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "class TemporalNetwork(nn.Module):\n",
    "    \"\"\"Temporal network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    z_dimension: int, (default=32)\n",
    "        Noise space dimension.\n",
    "    hid_channels: int, (default=1024)\n",
    "        Number of hidden channels.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        z_dimension: int = 32,\n",
    "        hid_channels: int = 1024,\n",
    "        n_bars: int = 2,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super().__init__()\n",
    "        self.n_bars = n_bars\n",
    "        self.net = nn.Sequential(\n",
    "            # input shape: (batch_size, z_dimension)\n",
    "            Reshape(shape=[z_dimension, 1, 1]),\n",
    "            # output shape: (batch_size, z_dimension, 1, 1)\n",
    "            nn.ConvTranspose2d(\n",
    "                z_dimension,\n",
    "                hid_channels,\n",
    "                kernel_size=(2, 1),\n",
    "                stride=(1, 1),\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.BatchNorm2d(hid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # output shape: (batch_size, hid_channels, 2, 1)\n",
    "            nn.ConvTranspose2d(\n",
    "                hid_channels,\n",
    "                z_dimension,\n",
    "                kernel_size=(self.n_bars - 1, 1),\n",
    "                stride=(1, 1),\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.BatchNorm2d(z_dimension),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # output shape: (batch_size, z_dimension, 1, 1)\n",
    "            Reshape(shape=[z_dimension, self.n_bars]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Perform forward.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: Tensor\n",
    "            Input batch.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tensor:\n",
    "            Preprocessed input batch.\n",
    "\n",
    "        \"\"\"\n",
    "        fx = self.net(x)\n",
    "        return fx\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\"\"\"Muse Generator.\"\"\"\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "class MuseGenerator(nn.Module):\n",
    "    \"\"\"Muse generator.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    z_dimension: int, (default=32)\n",
    "        Noise space dimension.\n",
    "    hid_channels: int, (default=1024)\n",
    "        Number of hidden channels.\n",
    "    hid_features: int, (default=1024)\n",
    "        Number of hidden features.\n",
    "    out_channels: int, (default=1)\n",
    "        Number of output channels.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        z_dimension: int = 32,\n",
    "        hid_channels: int = 1024,\n",
    "        hid_features: int = 1024,\n",
    "        out_channels: int = 1,\n",
    "        n_tracks: int = 4,\n",
    "        n_bars: int = 2,\n",
    "        n_steps_per_bar: int = 16,\n",
    "        n_pitches: int = 84,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super().__init__()\n",
    "        self.n_tracks = n_tracks\n",
    "        self.n_bars = n_bars\n",
    "        self.n_steps_per_bar = n_steps_per_bar\n",
    "        self.n_pitches = n_pitches\n",
    "        # chords generator\n",
    "        self.chords_network = TemporalNetwork(z_dimension, hid_channels, n_bars=n_bars)\n",
    "        # melody generators\n",
    "        self.melody_networks = nn.ModuleDict({})\n",
    "        for n in range(self.n_tracks):\n",
    "            self.melody_networks.add_module(\n",
    "                \"melodygen_\" + str(n),\n",
    "                TemporalNetwork(z_dimension, hid_channels, n_bars=n_bars),\n",
    "            )\n",
    "        # bar generators\n",
    "        self.bar_generators = nn.ModuleDict({})\n",
    "        for n in range(self.n_tracks):\n",
    "            self.bar_generators.add_module(\n",
    "                \"bargen_\" + str(n),\n",
    "                BarGenerator(\n",
    "                    z_dimension,\n",
    "                    hid_features,\n",
    "                    hid_channels // 2,\n",
    "                    out_channels,\n",
    "                    n_steps_per_bar=n_steps_per_bar,\n",
    "                    n_pitches=n_pitches,\n",
    "                )\n",
    "            )\n",
    "        # musegan generator compiled\n",
    "\n",
    "    def forward(self, chords: Tensor, style: Tensor, melody: Tensor, groove: Tensor) -> Tensor:\n",
    "        \"\"\"Perform forward.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        chords: Tensor\n",
    "            Chords.\n",
    "        style: Tensor\n",
    "            Style.\n",
    "        melody: Tensor\n",
    "            Melody.\n",
    "        groove: Tensor\n",
    "            Groove.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tensor:\n",
    "            Preprocessed input batch.\n",
    "\n",
    "        \"\"\"\n",
    "        # chords shape: (batch_size, z_dimension)\n",
    "        # style shape: (batch_size, z_dimension)\n",
    "        # melody shape: (batch_size, n_tracks, z_dimension)\n",
    "        # groove shape: (batch_size, n_tracks, z_dimension)\n",
    "        chord_outs = self.chords_network(chords)\n",
    "        bar_outs = []\n",
    "        for bar in range(self.n_bars):\n",
    "            track_outs = []\n",
    "            chord_out = chord_outs[:, :, bar]\n",
    "            style_out = style\n",
    "            for track in range(self.n_tracks):\n",
    "                melody_in = melody[:, track, :]\n",
    "                melody_out = self.melody_networks[\"melodygen_\" + str(track)](melody_in)[:, :, bar]\n",
    "                groove_out = groove[:, track, :]\n",
    "                z = torch.cat([chord_out, style_out, melody_out, groove_out], dim=1)\n",
    "                track_outs.append(self.bar_generators[\"bargen_\" + str(track)](z))\n",
    "            track_out = torch.cat(track_outs, dim=1)\n",
    "            bar_outs.append(track_out)\n",
    "        out = torch.cat(bar_outs, dim=2)\n",
    "        # out shape: (batch_size, n_tracks, n_bars, n_steps_per_bar, n_pitches)\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "\"\"\"Muse critic.\"\"\"\n",
    "\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "class MuseCritic(nn.Module):\n",
    "    \"\"\"Muse critic.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hid_channels: int, (default=128)\n",
    "        Number of hidden channels.\n",
    "    hid_features: int, (default=1024)\n",
    "        Number of hidden features.\n",
    "    out_channels: int, (default=1)\n",
    "        Number of output channels.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        hid_channels: int = 128,\n",
    "        hid_features: int = 1024,\n",
    "        out_features: int = 1,\n",
    "        n_tracks: int = 4,\n",
    "        n_bars: int = 2,\n",
    "        n_steps_per_bar: int = 16,\n",
    "        n_pitches: int = 84,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super().__init__()\n",
    "        self.n_tracks = n_tracks\n",
    "        self.n_bars = n_bars\n",
    "        self.n_steps_per_bar = n_steps_per_bar\n",
    "        self.n_pitches = n_pitches\n",
    "        in_features = 4 * hid_channels if n_bars == 2 else 12 * hid_channels\n",
    "        self.net = nn.Sequential(\n",
    "            # input shape: (batch_size, n_tracks, n_bars, n_steps_per_bar, n_pitches)\n",
    "            nn.Conv3d(self.n_tracks, hid_channels, (2, 1, 1), (1, 1, 1), padding=0),\n",
    "            nn.LeakyReLU(0.3, inplace=True),\n",
    "            # output shape: (batch_size, hid_channels, n_bars//2, n_steps_per_bar, n_pitches)\n",
    "            nn.Conv3d(hid_channels, hid_channels, (self.n_bars - 1, 1, 1), (1, 1, 1), padding=0),\n",
    "            nn.LeakyReLU(0.3, inplace=True),\n",
    "            # output shape: (batch_size, hid_channels, n_bars//2, n_steps_per_bar, n_pitches)\n",
    "            nn.Conv3d(hid_channels, hid_channels, (1, 1, 12), (1, 1, 12), padding=0),\n",
    "            nn.LeakyReLU(0.3, inplace=True),\n",
    "            # output shape: (batch_size, hid_channels, n_bars//2, n_steps_per_bar, n_pitches//12)\n",
    "            nn.Conv3d(hid_channels, hid_channels, (1, 1, 7), (1, 1, 7), padding=0),\n",
    "            nn.LeakyReLU(0.3, inplace=True),\n",
    "            # output shape: (batch_size, hid_channels, n_bars//2, n_steps_per_bar//2, n_pitches//12)\n",
    "            nn.Conv3d(hid_channels, hid_channels, (1, 2, 1), (1, 2, 1), padding=0),\n",
    "            nn.LeakyReLU(0.3, inplace=True),\n",
    "            # output shape: (batch_size, hid_channels, n_bars//2, n_steps_per_bar//4, n_pitches//12)\n",
    "            nn.Conv3d(hid_channels, hid_channels, (1, 2, 1), (1, 2, 1), padding=0),\n",
    "            nn.LeakyReLU(0.3, inplace=True),\n",
    "            # output shape: (batch_size, hid_channels, n_bars//2, n_steps_per_bar//4, n_pitches//12)\n",
    "            nn.Conv3d(hid_channels, 2 * hid_channels, (1, 4, 1), (1, 2, 1), padding=(0, 1, 0)),\n",
    "            nn.LeakyReLU(0.3, inplace=True),\n",
    "            # output shape: (batch_size, hid_channels, n_bars//2, n_steps_per_bar//8, n_pitches//12)\n",
    "            nn.Conv3d(2 * hid_channels, 4 * hid_channels, (1, 3, 1), (1, 2, 1), padding=(0, 1, 0)),\n",
    "            nn.LeakyReLU(0.3, inplace=True),\n",
    "            # output shape: (batch_size, hid_channels, n_bars//2, n_steps_per_bar//16, n_pitches//12)\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features, hid_features),\n",
    "            nn.LeakyReLU(0.3, inplace=True),\n",
    "            # output shape: (batch_size, hid_features)\n",
    "            nn.Linear(hid_features, out_features),\n",
    "            # output shape: (batch_size, out_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Perform forward.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: Tensor\n",
    "            Input batch.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tensor:\n",
    "            Preprocessed input batch.\n",
    "\n",
    "        \"\"\"\n",
    "        fx = self.net(x)\n",
    "        return fx\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cmaig\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\detection\\anchor_utils.py:63: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:68.)\n",
      "  device: torch.device = torch.device(\"cpu\"),\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import torch\n",
    "import torchvision.models\n",
    "from torch import nn\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "class MuseGan(nn.Module):\n",
    "    def __init__(self, experiment_dir=\"base_muse_gan\",\n",
    "                 reset=False, load_best=True):\n",
    "        super(MuseGan, self).__init__()\n",
    "        self.experiment_dir = experiment_dir\n",
    "        self.model_name = os.path.basename(self.experiment_dir)\n",
    "        self.reset = reset\n",
    "        self.load_best = load_best\n",
    "        self.setup_dirs()\n",
    "        self.setup_network()\n",
    "\n",
    "        if not reset: self.load_state()\n",
    "\n",
    "    ##1. Defining network architecture\n",
    "    def setup_network(self):\n",
    "        \"\"\"\n",
    "        Initialize the network  architecture here\n",
    "        @return:\n",
    "        \"\"\"\n",
    "\n",
    "        #1: load model config\n",
    "        config_file=os.path.join(self.experiment_dir,\"config.json\")\n",
    "        assert os.path.exists(config_file),f\"No config.json found in {self.experiment_dir}\"\n",
    "        model_config=read_json(config_file)\n",
    "        self.z_dimension =model_config[\"z_dimension\"]\n",
    "        self.g_channels =model_config[\"g_channels\"]\n",
    "        self.g_features =model_config[\"g_features\"]\n",
    "        self.c_channels =model_config[\"c_channels\"]\n",
    "        self.c_features = model_config[\"c_features\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        self.generator = MuseGenerator(\n",
    "            z_dimension=self.z_dimension,\n",
    "            hid_channels=self.g_channels,\n",
    "            hid_features=self.g_features,\n",
    "            out_channels=1,\n",
    "        ).to(device)\n",
    "        self.generator=MuseGenerator().apply(initialize_weights)\n",
    "\n",
    "\n",
    "        self.critic=MuseCritic(\n",
    "            hid_channels=self.c_channels,\n",
    "            hid_features=self.c_features,\n",
    "            out_features=1,\n",
    "\n",
    "        )\n",
    "        self.critic.apply(initialize_weights)\n",
    "\n",
    "\n",
    "    ##2. Model Saving/Loading\n",
    "    def load_state(self, best=False):\n",
    "        \"\"\"\n",
    "        Load model\n",
    "        :param self:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if best and os.path.exists(self.save_best_file):\n",
    "            logging.info(f\"Loading best model state : {self.save_file}\")\n",
    "            self.load_state_dict(torch.load(self.save_file, map_location=DEVICE))\n",
    "            return\n",
    "\n",
    "        if os.path.exists(self.save_file):\n",
    "            logging.info(f\"Loading model state : {self.save_file}\")\n",
    "            self.load_state_dict(torch.load(self.save_file, map_location=DEVICE))\n",
    "\n",
    "    def save_state(self, best=False):\n",
    "        if best:\n",
    "            logging.info(\"Saving best model\")\n",
    "            torch.save(self.state_dict(), self.save_best_file)\n",
    "        torch.save(self.state_dict(), self.save_file)\n",
    "\n",
    "    ##3. Setupping directories for weights /logs ... etc\n",
    "    def setup_dirs(self):\n",
    "        \"\"\"\n",
    "        Checking and creating directories for weights storage\n",
    "        @return:\n",
    "        \"\"\"\n",
    "        self.save_file = os.path.join(self.experiment_dir, f\"{self.model_name}.pt\")\n",
    "        self.save_best_file = os.path.join(self.experiment_dir, f\"{self.model_name}_best.pt\")\n",
    "        if not os.path.exists(self.experiment_dir):\n",
    "            os.makedirs(self.experiment_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "\"\"\"Midi dataset.\"\"\"\n",
    "from typing import Tuple\n",
    "from torch import Tensor\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from music21 import midi\n",
    "from music21 import converter\n",
    "from music21 import note, stream, duration, tempo\n",
    "class LPDDataset(Dataset):\n",
    "    \"\"\"LPDDataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        Path to dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        path: str,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        dataset = np.load(path, allow_pickle=True, encoding=\"bytes\")\n",
    "        self.data_binary = dataset[\"arr_0\"]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Return the number of samples in dataset.\"\"\"\n",
    "        return len(self.data_binary)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tensor:\n",
    "        \"\"\"Return one samples from dataset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        index: int\n",
    "            Index of sample.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tensor:\n",
    "            Sample.\n",
    "\n",
    "        \"\"\"\n",
    "        return torch.from_numpy(self.data_binary[index]).float()\n",
    "\n",
    "class MidiDataset(Dataset):\n",
    "    \"\"\"MidiDataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        Path to dataset.\n",
    "    split: str, optional (default=\"train\")\n",
    "        Split of dataset.\n",
    "    n_bars: int, optional (default=2)\n",
    "        Number of bars.\n",
    "    n_steps_per_bar: int, optional (default=16)\n",
    "        Number of steps per bar.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        path: str,\n",
    "        # split: str = \"train\",\n",
    "        split: str = \"train\",\n",
    "        n_bars: int = 2,\n",
    "        n_steps_per_bar: int = 16,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        self.n_bars = n_bars\n",
    "        self.n_steps_per_bar = n_steps_per_bar\n",
    "        dataset = np.load(path, allow_pickle=True, encoding=\"bytes\")[split]\n",
    "        self.data_binary, self.data_ints, self.data = self.__preprocess__(dataset)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Return the number of samples in dataset.\"\"\"\n",
    "        return len(self.data_binary)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tensor:\n",
    "        \"\"\"Return one samples from dataset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        index: int\n",
    "            Index of sample.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tensor:\n",
    "            Sample.\n",
    "\n",
    "        \"\"\"\n",
    "        return torch.from_numpy(self.data_binary[index]).float()\n",
    "\n",
    "    def __preprocess__(self, data: np.ndarray) -> Tuple[np.ndarray]:\n",
    "        \"\"\"Preprocess data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: np.ndarray\n",
    "            Data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray]:\n",
    "            Data binary, data ints, preprocessed data.\n",
    "\n",
    "        \"\"\"\n",
    "        data_ints = []\n",
    "        for x in data:\n",
    "            skip = True\n",
    "            skip_rows = 0\n",
    "            while skip:\n",
    "                if not np.any(np.isnan(x[skip_rows: skip_rows + 4])):\n",
    "                    skip = False\n",
    "                else:\n",
    "                    skip_rows += 4\n",
    "            if self.n_bars * self.n_steps_per_bar < x.shape[0]:\n",
    "                data_ints.append(x[skip_rows: self.n_bars * self.n_steps_per_bar + skip_rows, :])\n",
    "        data_ints = np.array(data_ints)\n",
    "        self.n_songs = data_ints.shape[0]\n",
    "        self.n_tracks = data_ints.shape[2]\n",
    "        data_ints = data_ints.reshape([self.n_songs, self.n_bars, self.n_steps_per_bar, self.n_tracks])\n",
    "        max_note = 83\n",
    "        mask = np.isnan(data_ints)\n",
    "        data_ints[mask] = max_note + 1\n",
    "        max_note = max_note + 1\n",
    "        data_ints = data_ints.astype(int)\n",
    "        num_classes = max_note + 1\n",
    "        data_binary = np.eye(num_classes)[data_ints]\n",
    "        data_binary[data_binary == 0] = -1\n",
    "        data_binary = np.delete(data_binary, max_note, -1)\n",
    "        data_binary = data_binary.transpose([0, 3, 1, 2, 4])\n",
    "        return data_binary, data_ints, data\n",
    "\n",
    "\n",
    "def binarise_output(output: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Binarize output.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    output: np.ndarray\n",
    "        Output array.\n",
    "\n",
    "    \"\"\"\n",
    "    max_pitches = np.argmax(output, axis=-1)\n",
    "    return max_pitches\n",
    "\n",
    "\n",
    "def postprocess(\n",
    "    output: np.ndarray,\n",
    "    n_tracks: int = 4,\n",
    "    n_bars: int = 2,\n",
    "    n_steps_per_bar: int = 16,\n",
    ") -> stream.Score:\n",
    "    \"\"\"Postprocess output.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    output: np.ndarray\n",
    "        Output array.\n",
    "    n_tracks: int, (default=4)\n",
    "        Number of tracks.\n",
    "    n_bars: int, (default=2)\n",
    "        Number of bars.\n",
    "    n_steps_per_bar: int, (default=16)\n",
    "        Number of steps per bar.\n",
    "\n",
    "    \"\"\"\n",
    "    parts = stream.Score()\n",
    "    parts.append(tempo.MetronomeMark(number=66))\n",
    "    max_pitches = binarise_output(output)\n",
    "    midi_note_score = np.vstack([\n",
    "        max_pitches[i].reshape([n_bars * n_steps_per_bar, n_tracks]) for i in range(len(output))\n",
    "    ])\n",
    "    for i in range(n_tracks):\n",
    "        last_x = int(midi_note_score[:, i][0])\n",
    "        s = stream.Part()\n",
    "        dur = 0\n",
    "        for idx, x in enumerate(midi_note_score[:, i]):\n",
    "            x = int(x)\n",
    "            if (x != last_x or idx % 4 == 0) and idx > 0:\n",
    "                n = note.Note(last_x)\n",
    "                n.duration = duration.Duration(dur)\n",
    "                s.append(n)\n",
    "                dur = 0\n",
    "            last_x = x\n",
    "            dur = dur + 0.25\n",
    "        n = note.Note(last_x)\n",
    "        n.duration = duration.Duration(dur)\n",
    "        s.append(n)\n",
    "        parts.append(s)\n",
    "    return parts\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loss and metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "\n",
    "from torch import Tensor\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class WassersteinLoss(nn.Module):\n",
    "    \"\"\"WassersteinLoss.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, y_pred: Tensor, y_target: Tensor) -> Tensor:\n",
    "        \"\"\"Calculate Wasserstein loss.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred: Tensor\n",
    "            Prediction.\n",
    "        y_target: Tensor\n",
    "            Target.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tensor:\n",
    "            Loss value.\n",
    "\n",
    "        \"\"\"\n",
    "        loss = - torch.mean(y_pred * y_target)\n",
    "        return loss\n",
    "\n",
    "class GradientPenalty(nn.Module):\n",
    "    \"\"\"Gradient penalty.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, inputs: Tensor, outputs: Tensor) -> Tensor:\n",
    "        \"\"\"Calculate gradient penalty.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs: Tensor\n",
    "            Input from which to track gradient.\n",
    "        outputs: Tensor\n",
    "            Output to which to track gradient.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tensor:\n",
    "            Penalty value.\n",
    "\n",
    "        \"\"\"\n",
    "        grad = torch.autograd.grad(\n",
    "            inputs=inputs,\n",
    "            outputs=outputs,\n",
    "            grad_outputs=torch.ones_like(outputs),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "        )[0]\n",
    "        grad_ = torch.norm(grad.view(grad.size(0), -1), p=2, dim=1)\n",
    "        penalty = torch.mean((1. - grad_) ** 2)\n",
    "        return penalty\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Trainer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "class Trainer:\n",
    "    \"\"\"\n",
    "    Class to manage the full training pipeline\n",
    "    \"\"\"\n",
    "    def __init__(self, network:MuseGan,\n",
    "                 g_optimizer,\n",
    "                 c_optimizer,\n",
    "                 nb_epochs=10,\n",
    "                 repeat=5,\n",
    "                 batch_size=128,\n",
    "                 reset=False):\n",
    "        \"\"\"\n",
    "        @param network:\n",
    "        @param dataset_name:\n",
    "        @param images_dirs:\n",
    "        @param loss:\n",
    "        @param optimizer:\n",
    "        @param nb_epochs:\n",
    "        @param nb_workers: Number of worker for the dataloader\n",
    "        \"\"\"\n",
    "        self.network = network\n",
    "        self.batch_size = batch_size\n",
    "        self.repeat=repeat\n",
    "        self.g_optimizer=g_optimizer\n",
    "        self.c_optimizer = c_optimizer\n",
    "\n",
    "        self.g_criterion = WassersteinLoss().to(DEVICE)\n",
    "        self.c_criterion = WassersteinLoss().to(DEVICE)\n",
    "\n",
    "\n",
    "        self.c_penalty=GradientPenalty().to(DEVICE)\n",
    "\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.experiment_dir = self.network.experiment_dir\n",
    "        self.model_info_file = os.path.join(self.experiment_dir, \"model.json\")\n",
    "        self.model_info_best_file = os.path.join(self.experiment_dir, \"model_best.json\")\n",
    "\n",
    "        if reset:\n",
    "            if os.path.exists(self.experiment_dir):\n",
    "                shutil.rmtree(self.experiment_dir)\n",
    "        if not os.path.exists(self.experiment_dir):\n",
    "            os.makedirs(self.experiment_dir)\n",
    "\n",
    "        self.start_epoch = 0\n",
    "        if not reset and os.path.exists(self.model_info_file):\n",
    "            with open(self.model_info_file, \"r\") as f:\n",
    "                self.start_epoch = json.load(f)[\"epoch\"] + 1\n",
    "                self.nb_epochs += self.start_epoch\n",
    "                logging.info(\"Resuming from epoch {}\".format(self.start_epoch))\n",
    "\n",
    "\n",
    "    def save_model_info(self, infos, best=False):\n",
    "        json.dump(infos, open(self.model_info_file, 'w'),indent=4)\n",
    "        if best: json.dump(infos, open(self.model_info_best_file, 'w'),indent=4)\n",
    "\n",
    "    def fit(self,train_dataloader):\n",
    "        logging.info(\"Launch training on {}\".format(DEVICE))\n",
    "        self.network.train()\n",
    "        self.network.to(DEVICE)\n",
    "        self.summary_writer = SummaryWriter(log_dir=self.experiment_dir)\n",
    "        itr = self.start_epoch * len(train_dataloader) * self.batch_size  ##Global counter for steps\n",
    "        if os.path.exists(self.model_info_file):\n",
    "            with open(self.model_info_file, \"r\") as f:\n",
    "                model_info = json.load(f)\n",
    "                lr=model_info[\"lr\"]\n",
    "                logging.info(f\"Setting lr to {lr}\")\n",
    "                for g in self.optimizer.param_groups:\n",
    "                    g['lr'] = lr\n",
    "        if os.path.exists(self.model_info_best_file):\n",
    "            with open(self.model_info_best_file, \"r\") as f:\n",
    "                best_model_info = json.load(f)\n",
    "                best_loss = best_model_info[\"val_loss\"]\n",
    "\n",
    "        self.alpha = torch.rand((self.batch_size, 1, 1, 1, 1)).requires_grad_().to(DEVICE)\n",
    "        for epoch in range(self.start_epoch, self.nb_epochs):  # Training loop\n",
    "            epoch_gloss = Averager()\n",
    "            epoch_cfloss = Averager()\n",
    "            epoch_crloss = Averager()\n",
    "            epoch_cploss = Averager()\n",
    "            epoch_closs = Averager()\n",
    "            pbar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{self.nb_epochs}\")\n",
    "            for _, real in enumerate(pbar):\n",
    "                \"\"\"\n",
    "                Training lopp\n",
    "                \"\"\"\n",
    "\n",
    "                #Train the critic\n",
    "                real=real.to(DEVICE)\n",
    "                batch_closs = Averager()\n",
    "                batch_cfloss = Averager()\n",
    "                batch_crloss = Averager()\n",
    "                batch_cploss = Averager()\n",
    "                for _ in range(self.repeat):\n",
    "                    cords = torch.randn(self.batch_size, 32).to(DEVICE)\n",
    "                    style = torch.randn(self.batch_size, 32).to(DEVICE)\n",
    "                    melody = torch.randn(self.batch_size, 4, 32).to(DEVICE)\n",
    "                    groove = torch.randn(self.batch_size, 4, 32).to(DEVICE)\n",
    "\n",
    "                    self.c_optimizer.zero_grad()\n",
    "                    with torch.no_grad():\n",
    "                        fake = self.network.generator(cords, style, melody, groove).detach()\n",
    "                    realfake = self.alpha * real + (1. - self.alpha) * fake\n",
    "\n",
    "                    fake_pred = self.network.critic(fake)\n",
    "                    real_pred = self.network.critic(real)\n",
    "                    realfake_pred = self.network.critic(realfake)\n",
    "                    fake_loss = self.c_criterion(fake_pred, - torch.ones_like(fake_pred))\n",
    "                    real_loss = self.c_criterion(real_pred, torch.ones_like(real_pred))\n",
    "                    penalty = self.c_penalty(realfake, realfake_pred)\n",
    "                    closs = fake_loss + real_loss + 10 * penalty\n",
    "                    closs.backward(retain_graph=True)\n",
    "                    self.c_optimizer.step()\n",
    "                    batch_cfloss.send(fake_loss.item())\n",
    "                    batch_crloss.send(real_loss.item())\n",
    "                    batch_cploss.send(10 * penalty.item())\n",
    "                    batch_closs.send(closs.item() / self.repeat)\n",
    "\n",
    "\n",
    "                # Train Generator\n",
    "                self.g_optimizer.zero_grad()\n",
    "                cords = torch.randn(self.batch_size, 32).to(DEVICE)\n",
    "                style = torch.randn(self.batch_size, 32).to(DEVICE)\n",
    "                melody = torch.randn(self.batch_size, 4, 32).to(DEVICE)\n",
    "                groove = torch.randn(self.batch_size, 4, 32).to(DEVICE)\n",
    "\n",
    "                fake = self.network.generator(cords, style, melody, groove)\n",
    "                fake_pred = self.network.critic(fake)\n",
    "                b_gloss = self.g_criterion(fake_pred, torch.ones_like(fake_pred))\n",
    "                b_gloss.backward()\n",
    "                self.g_optimizer.step()\n",
    "\n",
    "                \"\"\"\n",
    "                4.Writing logs and tensorboard data, loss and other metrics\n",
    "                \"\"\"\n",
    "                batch_data={\n",
    "                \"generator_loss\":b_gloss.item(),\n",
    "                \"critic_loss\":batch_closs.value,\n",
    "                \"critic_fake_loss\":batch_cfloss.value,\n",
    "                \"critic_real_loss\":batch_crloss.value,\n",
    "                \"critic_penalized_loss\":batch_cploss.value\n",
    "                    }\n",
    "\n",
    "                for k,v in batch_data.items():\n",
    "                    self.summary_writer.add_scalar(f\"Train steps/{k}\", v, itr)\n",
    "\n",
    "                epoch_gloss.send(b_gloss.item())\n",
    "                epoch_cfloss.send(batch_cfloss.value)\n",
    "                epoch_crloss.send(batch_crloss.value)\n",
    "                epoch_cploss.send(batch_cploss.value)\n",
    "                epoch_closs.send(batch_closs.value)\n",
    "\n",
    "\n",
    "            epoch_data={\n",
    "                \"generator_loss\":epoch_gloss.value,\n",
    "                \"critic_loss\":epoch_closs.value,\n",
    "                \"critic_fake_loss\":epoch_cfloss.value,\n",
    "                \"critic_real_loss\":epoch_crloss.value,\n",
    "                \"critic_penalized_loss\":epoch_cploss.value\n",
    "            }\n",
    "            for k,v in epoch_data.items():\n",
    "                self.summary_writer.add_scalar(f\"Train epochs/{k}\",v,epoch)\n",
    "            logging.info(f\"Epoch {epoch}/{self.nb_epochs} | Generator loss: {epoch_gloss.value:.3f} | Critic loss: {epoch_closs.value:.3f}\")\n",
    "            # logging.info(f\"(fake: {epoch_cfloss.value:.3f}, real: {epoch_crloss.value:.3f}, penalty: {epoch_cploss.value:.3f})\")\n",
    "\n",
    "            #TODO write epoch metrics results\n",
    "            infos = epoch_data\n",
    "            infos[\"epoch\"]=epoch\n",
    "            self.network.save_state()\n",
    "            self.save_model_info(infos)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Runner"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import torch.utils.data\n",
    "from torch.optim import Adam\n",
    "\n",
    "def main(args):\n",
    "    model_name = \"base_model\" if args.model_name is None else args.model_name\n",
    "    experiment_dir = os.path.join(EXPERIMENTS_DIR, model_name)\n",
    "    config_file=os.path.join(experiment_dir,\"config.json\")\n",
    "\n",
    "    if not os.path.exists(experiment_dir):os.makedirs(experiment_dir)\n",
    "    if  not os.path.exists(config_file) or args.reset:\n",
    "        model_config={\n",
    "        \"z_dimension\":args.z_dimension,\n",
    "        \"g_channels\": args.g_channels,\n",
    "        \"g_features\" : args.g_features,\n",
    "        \"c_channels\" : args.c_channels,\n",
    "        \"c_features\" : args.c_features,\n",
    "        }\n",
    "        with open(config_file,\"w\") as f:json.dump(model_config,f,indent=4)\n",
    "\n",
    "\n",
    "\n",
    "    network=MuseGan(experiment_dir=experiment_dir,\n",
    "                    reset=args.reset,\n",
    "\n",
    "                    )\n",
    "\n",
    "\n",
    "    g_optimizer = Adam(network.generator.parameters(),lr=args.g_lr,betas=(0.5, 0.9))\n",
    "    c_optimizer = Adam(network.critic.parameters(),lr=args.c_lr,betas=(0.5, 0.9))\n",
    "\n",
    "    logging.info(\"Training : \"+model_name)\n",
    "    trainer = Trainer(network,\n",
    "                      g_optimizer,\n",
    "                      c_optimizer,\n",
    "                      nb_epochs= args.nb_epochs,\n",
    "                      batch_size=args.batch_size,\n",
    "                      reset=args.reset,\n",
    "                      )\n",
    "\n",
    "    train_dataset=MidiDataset(DATASET_FILE, split=\"nonzero\")\n",
    "    train_dataloader=torch.utils.data.DataLoader(train_dataset,batch_size=args.batch_size,num_workers=args.num_workers,shuffle=True,drop_last=True)\n",
    "    trainer.fit(train_dataloader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EXPERIMENTS_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [27]\u001B[0m, in \u001B[0;36m<cell line: 19>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m args\u001B[38;5;241m=\u001B[39m{\n\u001B[0;32m      2\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreset\u001B[39m\u001B[38;5;124m\"\u001B[39m:\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m      3\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlearning_rate\u001B[39m\u001B[38;5;124m\"\u001B[39m:\u001B[38;5;241m0.001\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     15\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlog_level\u001B[39m\u001B[38;5;124m\"\u001B[39m:\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mINFO\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     16\u001B[0m         }\n\u001B[0;32m     17\u001B[0m args\u001B[38;5;241m=\u001B[39mnamedtuple(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124margs\u001B[39m\u001B[38;5;124m\"\u001B[39m,args\u001B[38;5;241m.\u001B[39mkeys())(\u001B[38;5;241m*\u001B[39margs\u001B[38;5;241m.\u001B[39mvalues())\n\u001B[1;32m---> 19\u001B[0m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [25]\u001B[0m, in \u001B[0;36mmain\u001B[1;34m(args)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmain\u001B[39m(args):\n\u001B[0;32m     10\u001B[0m     model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbase_model\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m args\u001B[38;5;241m.\u001B[39mmodel_name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m args\u001B[38;5;241m.\u001B[39mmodel_name\n\u001B[1;32m---> 11\u001B[0m     experiment_dir \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[43mEXPERIMENTS_DIR\u001B[49m, model_name)\n\u001B[0;32m     12\u001B[0m     config_file\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(experiment_dir,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconfig.json\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(experiment_dir):os\u001B[38;5;241m.\u001B[39mmakedirs(experiment_dir)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'EXPERIMENTS_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "args={\n",
    "        \"reset\":False,\n",
    "        \"learning_rate\":0.001,\n",
    "        \"nb_epochs\":20,\n",
    "        \"model_name\":\"base_muse_gan\",\n",
    "        \"num_workers\":4,\n",
    "        \"batch_size\":128,\n",
    "        \"z_dimension\":32,\n",
    "        \"g_channels\":1024,\n",
    "        \"g_features\":1024,\n",
    "        \"g_lr\":0.001,\n",
    "        \"c_channels\":128,\n",
    "        \"c_features\":1024,\n",
    "        \"c_lr\":0.001,\n",
    "        \"log_level\":\"INFO\"\n",
    "        }\n",
    "args=namedtuple(\"args\",args.keys())(*args.values())\n",
    "\n",
    "main(args)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}