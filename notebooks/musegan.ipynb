{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup\n","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"!pip install SharedArray\n!pip install music21","metadata":{"execution":{"iopub.status.busy":"2022-09-18T11:16:45.713266Z","iopub.execute_input":"2022-09-18T11:16:45.713904Z","iopub.status.idle":"2022-09-18T11:17:16.335193Z","shell.execute_reply.started":"2022-09-18T11:16:45.713803Z","shell.execute_reply":"2022-09-18T11:17:16.333975Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting SharedArray\n  Downloading SharedArray-3.2.1.tar.gz (22 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from SharedArray) (1.21.6)\nBuilding wheels for collected packages: SharedArray\n  Building wheel for SharedArray (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for SharedArray: filename=SharedArray-3.2.1-cp37-cp37m-linux_x86_64.whl size=82718 sha256=f2ce481c49b3e6b5eda97842c1393ce2f6fa9b697434e5670c62c97f72df1a1a\n  Stored in directory: /root/.cache/pip/wheels/75/04/e3/ac4ce722fc1c8ba9ac37b5048df91673f9cd9800d459f55940\nSuccessfully built SharedArray\nInstalling collected packages: SharedArray\nSuccessfully installed SharedArray-3.2.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting music21\n  Downloading music21-7.3.3-py3-none-any.whl (22.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from music21) (1.21.6)\nCollecting jsonpickle\n  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from music21) (1.0.1)\nRequirement already satisfied: chardet in /opt/conda/lib/python3.7/site-packages (from music21) (5.0.0)\nRequirement already satisfied: more-itertools in /opt/conda/lib/python3.7/site-packages (from music21) (8.14.0)\nCollecting webcolors>=1.5\n  Downloading webcolors-1.12-py3-none-any.whl (9.9 kB)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from music21) (3.5.3)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from jsonpickle->music21) (4.12.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->music21) (1.4.3)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->music21) (3.0.9)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->music21) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->music21) (9.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->music21) (2.8.2)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->music21) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->music21) (4.33.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->music21) (4.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->music21) (1.15.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonpickle->music21) (3.8.0)\nInstalling collected packages: webcolors, jsonpickle, music21\nSuccessfully installed jsonpickle-2.2.0 music21-7.3.3 webcolors-1.12\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport torch\nROOT_DIR=\"/kaggle/working\"\nDATASET_FILE=\"../input/lpd5-processed/train_x_lpd_5_phr_processed.npz\"\n# DATASET_FILE=os.path.join(DATA_DIR,\"Jsb16thSeparated.npz\")\nEXPERIMENTS_DIR=os.path.join(ROOT_DIR, \"logs/experiments\")\nuse_cuda = torch .cuda.is_available()\nDEVICE = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-18T11:17:16.338866Z","iopub.execute_input":"2022-09-18T11:17:16.339210Z","iopub.status.idle":"2022-09-18T11:17:18.079440Z","shell.execute_reply.started":"2022-09-18T11:17:16.339177Z","shell.execute_reply":"2022-09-18T11:17:18.078295Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"os.path.exists(DATASET_FILE)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-18T11:17:18.080839Z","iopub.execute_input":"2022-09-18T11:17:18.081498Z","iopub.status.idle":"2022-09-18T11:17:18.095402Z","shell.execute_reply.started":"2022-09-18T11:17:18.081460Z","shell.execute_reply":"2022-09-18T11:17:18.094574Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"## Utils","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"import logging\nimport os\nimport sys\nfrom time import strftime\ndef setup_logger(args):\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    a_logger = logging.getLogger()\n    a_logger.setLevel(args.log_level)\n    log_dir=os.path.join(ROOT_DIR,\"logs\",\"output_logs\")\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    output_file_handler = logging.FileHandler(os.path.join(log_dir,strftime(\"log_%d_%m_%Y_%H_%M.log\")))\n    stdout_handler = logging.StreamHandler(sys.stdout)\n    stdout_handler.setFormatter(formatter)\n    a_logger.propagate=False\n    a_logger.addHandler(output_file_handler)\n    a_logger.addHandler(stdout_handler)\n\nimport json\nimport os\nfrom enum import Enum\nfrom itertools import islice\nimport numpy as np\n\ndef read_json(path_json):\n    with open(path_json, encoding='utf8') as json_file:\n        return json.load(json_file)\ndef softmax(x):\n    return np.exp(x) / np.sum(np.exp(x))\ndef chunks(data, SIZE):\n    \"\"\"Split a dictionnary into parts of max_size =SIZE\"\"\"\n    it = iter(data)\n    for _ in range(0, len(data), SIZE):\n        yield {k: data[k] for k in islice(it, SIZE)}\n\ndef sorted_dict(x, ascending=True):\n    \"\"\"\n    Sort dict according to value.\n    x must be a primitive type: int,float, str...\n    @param x:\n    @return:\n    \"\"\"\n    return dict(sorted(x.items(), key=lambda item: (1 if ascending else -1) * item[1]))\ndef reverse_dict(input_dict):\n    \"\"\"\n    Reverse a dictonary\n    Args:\n        input_dict:\n\n    Returns:\n\n    \"\"\"\n    inv_dict = {}\n    for k, v in input_dict.items():\n        inv_dict[v] = inv_dict.get(v, []) + [k]\n\n    return inv_dict\n\ndef save_matrix(matrix,filename):\n    with open(filename,'wb') as output:\n        np.save(output,matrix)\ndef load_matrix(filename,auto_delete=False):\n    with open(filename,'rb') as input:\n        matrix=np.load(input)\n\n    if auto_delete:\n        os.remove(filename)\n    return matrix\n\n\n\nclass Averager:\n    def __init__(self):\n        self.current_total = 0.0\n        self.iterations = 0.0\n\n    def send(self, value):\n        self.current_total += value\n        self.iterations += 1\n\n    @property\n    def value(self):\n        if self.iterations == 0:\n            return 0\n        else:\n            return 1.0 * self.current_total / self.iterations\n\n    def reset(self):\n        self.current_total = 0.0\n        self.iterations = 0.0","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-18T11:17:18.098691Z","iopub.execute_input":"2022-09-18T11:17:18.100171Z","iopub.status.idle":"2022-09-18T11:17:18.115172Z","shell.execute_reply.started":"2022-09-18T11:17:18.100135Z","shell.execute_reply":"2022-09-18T11:17:18.114347Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Network","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"\"\"\"Utils.\"\"\"\nfrom typing import List\nfrom torch import Tensor\nfrom torch import nn\ndef initialize_weights(layer: nn.Module, mean: float = 0.0, std: float = 0.02):\n    \"\"\"Initialize module with normal distribution.\n\n    Parameters\n    ----------\n    layer: nn.Module\n        Layer.\n    mean: float, (default=0.0)\n        Mean value.\n    std: float, (default=0.02)\n        Standard deviation value.\n\n    \"\"\"\n    if isinstance(layer, (nn.Conv3d, nn.ConvTranspose2d)):\n        torch.nn.init.normal_(layer.weight, mean, std)\n    elif isinstance(layer, (nn.Linear, nn.BatchNorm2d)):\n        torch.nn.init.normal_(layer.weight, mean, std)\n        torch.nn.init.constant_(layer.bias, 0)\n\n\nclass Reshape(nn.Module):\n    \"\"\"Reshape layer.\n\n    Parameters\n    ----------\n    shape: List[int]\n        Dimensions after number of batches.\n\n    \"\"\"\n\n    def __init__(self, shape: List[int]) -> None:\n        \"\"\"Initialize.\"\"\"\n        super().__init__()\n        self.shape = shape\n\n    def forward(self, x: Tensor) -> Tensor:\n        \"\"\"Perform forward.\n\n        Parameters\n        ----------\n        x: Tensor\n            Input batch.\n\n        Returns\n        -------\n        Tensor:\n            Preprocessed input batch.\n\n        \"\"\"\n        return x.view(x.size(0), *self.shape)\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-18T11:17:18.118261Z","iopub.execute_input":"2022-09-18T11:17:18.118531Z","iopub.status.idle":"2022-09-18T11:17:18.129584Z","shell.execute_reply.started":"2022-09-18T11:17:18.118506Z","shell.execute_reply":"2022-09-18T11:17:18.128602Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\"\"\"Bar Generator.\"\"\"\n\nfrom torch import Tensor\nfrom torch import nn\nclass BarGenerator(nn.Module):\n    \"\"\"Bar generator.\n\n    Parameters\n    ----------\n    z_dimension: int, (default=32)\n        Noise space dimension.\n    hid_channels: int, (default=1024)\n        Number of hidden channels.\n    hid_features: int, (default=1024)\n        Number of hidden features.\n    out_channels: int, (default=1)\n        Number of output channels.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        z_dimension: int = 32,\n        hid_features: int = 1024,\n        hid_channels: int = 512,\n        out_channels: int = 1,\n        n_steps_per_bar = 16,\n        n_pitches = 84,\n    ) -> None:\n        \"\"\"Initialize.\"\"\"\n        super().__init__()\n        self.n_steps_per_bar = n_steps_per_bar\n        self.n_pitches = n_pitches\n        self.net = nn.Sequential(\n            # input shape: (batch_size, 4*z_dimension)\n            nn.Linear(4 * z_dimension, hid_features),\n            nn.BatchNorm1d(hid_features),\n            nn.ReLU(inplace=True),\n            # output shape: (batch_size, hid_features)\n            Reshape(shape=[hid_channels, hid_features // hid_channels, 1]),\n            # output shape: (batch_size, hid_channels, hid_features//hid_channels, 1)\n            nn.ConvTranspose2d(\n                hid_channels,\n                hid_channels,\n                kernel_size=(2, 1),\n                stride=(2, 1),\n                padding=0,\n            ),\n            nn.BatchNorm2d(hid_channels),\n            nn.ReLU(inplace=True),\n            # output shape: (batch_size, hid_channels, 2*hid_features//hid_channels, 1)\n            nn.ConvTranspose2d(\n                hid_channels,\n                hid_channels // 2,\n                kernel_size=(2, 1),\n                stride=(2, 1),\n                padding=0,\n            ),\n            nn.BatchNorm2d(hid_channels // 2),\n            nn.ReLU(inplace=True),\n            # output shape: (batch_size, hid_channels//2, 4*hid_features//hid_channels, 1)\n            nn.ConvTranspose2d(\n                hid_channels // 2,\n                hid_channels // 2,\n                kernel_size=(2, 1),\n                stride=(2, 1),\n                padding=0,\n            ),\n            nn.BatchNorm2d(hid_channels // 2),\n            nn.ReLU(inplace=True),\n            # output shape: (batch_size, hid_channels//2, 8*hid_features//hid_channels, 1)\n            nn.ConvTranspose2d(\n                hid_channels // 2,\n                hid_channels // 2,\n                kernel_size=(1, 7),\n                stride=(1, 7),\n                padding=0,\n            ),\n            nn.BatchNorm2d(hid_channels // 2),\n            nn.ReLU(inplace=True),\n            # output shape: (batch_size, hid_channels//2, 8*hid_features//hid_channels, 7)\n            nn.ConvTranspose2d(\n                hid_channels // 2,\n                out_channels,\n                kernel_size=(1, 12),\n                stride=(1, 12),\n                padding=0,\n            ),\n\n            # output shape: (batch_size, out_channels, 8*hid_features//hid_channels, n_pitches)\n            #My update\n            nn.Flatten(),\n            nn.Linear(out_channels*8*hid_features//hid_channels*n_pitches,self.n_steps_per_bar*self.n_pitches),\n            #End of my update\n\n\n            Reshape(shape=[1, 1, self.n_steps_per_bar, self.n_pitches])\n            # output shape: (batch_size, out_channels, 1, n_steps_per_bar, n_pitches)\n        )\n\n    def forward(self, x: Tensor) -> Tensor:\n        \"\"\"Perform forward.\n\n        Parameters\n        ----------\n        x: Tensor\n            Input batch.\n\n        Returns\n        -------\n        Tensor:\n            Preprocessed input batch.\n\n        \"\"\"\n        fx = self.net(x)\n        return fx","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-18T11:17:18.133076Z","iopub.execute_input":"2022-09-18T11:17:18.133711Z","iopub.status.idle":"2022-09-18T11:17:18.148772Z","shell.execute_reply.started":"2022-09-18T11:17:18.133685Z","shell.execute_reply":"2022-09-18T11:17:18.147842Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\"\"\"Temporal Network.\"\"\"\n\nfrom torch import Tensor\n\nimport torch\nfrom torch import nn\nclass TemporalNetwork(nn.Module):\n    \"\"\"Temporal network.\n\n    Parameters\n    ----------\n    z_dimension: int, (default=32)\n        Noise space dimension.\n    hid_channels: int, (default=1024)\n        Number of hidden channels.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        z_dimension: int = 32,\n        hid_channels: int = 1024,\n        n_bars: int = 2,\n    ) -> None:\n        \"\"\"Initialize.\"\"\"\n        super().__init__()\n        self.n_bars = n_bars\n        self.net = nn.Sequential(\n            # input shape: (batch_size, z_dimension)\n            Reshape(shape=[z_dimension, 1, 1]),\n            # output shape: (batch_size, z_dimension, 1, 1)\n            nn.ConvTranspose2d(\n                z_dimension,\n                hid_channels,\n                kernel_size=(2, 1),\n                stride=(1, 1),\n                padding=0,\n            ),\n            nn.BatchNorm2d(hid_channels),\n            nn.ReLU(inplace=True),\n            # output shape: (batch_size, hid_channels, 2, 1)\n            nn.ConvTranspose2d(\n                hid_channels,\n                z_dimension,\n                kernel_size=(self.n_bars - 1, 1),\n                stride=(1, 1),\n                padding=0,\n            ),\n            nn.BatchNorm2d(z_dimension),\n            nn.ReLU(inplace=True),\n            # output shape: (batch_size, z_dimension, 1, 1)\n            Reshape(shape=[z_dimension, self.n_bars]),\n        )\n\n    def forward(self, x: Tensor) -> Tensor:\n        \"\"\"Perform forward.\n\n        Parameters\n        ----------\n        x: Tensor\n            Input batch.\n\n        Returns\n        -------\n        Tensor:\n            Preprocessed input batch.\n\n        \"\"\"\n        fx = self.net(x)\n        return fx\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-18T11:17:18.150375Z","iopub.execute_input":"2022-09-18T11:17:18.150792Z","iopub.status.idle":"2022-09-18T11:17:18.162197Z","shell.execute_reply.started":"2022-09-18T11:17:18.150758Z","shell.execute_reply":"2022-09-18T11:17:18.161230Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\"\"\"Muse Generator.\"\"\"\n\nfrom torch import Tensor\n\nimport torch\nfrom torch import nn\nclass MuseGenerator(nn.Module):\n    \"\"\"Muse generator.\n\n    Parameters\n    ----------\n    z_dimension: int, (default=32)\n        Noise space dimension.\n    hid_channels: int, (default=1024)\n        Number of hidden channels.\n    hid_features: int, (default=1024)\n        Number of hidden features.\n    out_channels: int, (default=1)\n        Number of output channels.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        z_dimension: int = 32,\n        hid_channels: int = 1024,\n        hid_features: int = 1024,\n        out_channels: int = 1,\n        n_tracks: int = 4,\n        n_bars: int = 2,\n        n_steps_per_bar: int = 16,\n        n_pitches: int = 84,\n    ) -> None:\n        \"\"\"Initialize.\"\"\"\n        super().__init__()\n        self.n_tracks = n_tracks\n        self.n_bars = n_bars\n        self.n_steps_per_bar = n_steps_per_bar\n        self.n_pitches = n_pitches\n        # chords generator\n        self.chords_network = TemporalNetwork(z_dimension, hid_channels, n_bars=n_bars)\n        # melody generators\n        self.melody_networks = nn.ModuleDict({})\n        for n in range(self.n_tracks):\n            self.melody_networks.add_module(\n                \"melodygen_\" + str(n),\n                TemporalNetwork(z_dimension, hid_channels, n_bars=n_bars),\n            )\n        # bar generators\n        self.bar_generators = nn.ModuleDict({})\n        for n in range(self.n_tracks):\n            self.bar_generators.add_module(\n                \"bargen_\" + str(n),\n                BarGenerator(\n                    z_dimension,\n                    hid_features,\n                    hid_channels // 2,\n                    out_channels,\n                    n_steps_per_bar=n_steps_per_bar,\n                    n_pitches=n_pitches,\n                )\n            )\n        # musegan generator compiled\n\n    def forward(self, chords: Tensor, style: Tensor, melody: Tensor, groove: Tensor) -> Tensor:\n        \"\"\"Perform forward.\n\n        Parameters\n        ----------\n        chords: Tensor\n            Chords.\n        style: Tensor\n            Style.\n        melody: Tensor\n            Melody.\n        groove: Tensor\n            Groove.\n\n        Returns\n        -------\n        Tensor:\n            Preprocessed input batch.\n\n        \"\"\"\n        # chords shape: (batch_size, z_dimension)\n        # style shape: (batch_size, z_dimension)\n        # melody shape: (batch_size, n_tracks, z_dimension)\n        # groove shape: (batch_size, n_tracks, z_dimension)\n        chord_outs = self.chords_network(chords)\n        bar_outs = []\n        for bar in range(self.n_bars):\n            track_outs = []\n            chord_out = chord_outs[:, :, bar]\n            style_out = style\n            for track in range(self.n_tracks):\n                melody_in = melody[:, track, :]\n                melody_out = self.melody_networks[\"melodygen_\" + str(track)](melody_in)[:, :, bar]\n                groove_out = groove[:, track, :]\n                z = torch.cat([chord_out, style_out, melody_out, groove_out], dim=1)\n                track_outs.append(self.bar_generators[\"bargen_\" + str(track)](z))\n            track_out = torch.cat(track_outs, dim=1)\n            bar_outs.append(track_out)\n        out = torch.cat(bar_outs, dim=2)\n        # out shape: (batch_size, n_tracks, n_bars, n_steps_per_bar, n_pitches)\n        return out\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-18T11:17:18.163528Z","iopub.execute_input":"2022-09-18T11:17:18.164022Z","iopub.status.idle":"2022-09-18T11:17:18.179730Z","shell.execute_reply.started":"2022-09-18T11:17:18.163984Z","shell.execute_reply":"2022-09-18T11:17:18.178808Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\"\"\"Muse critic.\"\"\"\n\nfrom torch import Tensor\nfrom torch import nn\nclass MuseCritic(nn.Module):\n    \"\"\"Muse critic.\n\n    Parameters\n    ----------\n    hid_channels: int, (default=128)\n        Number of hidden channels.\n    hid_features: int, (default=1024)\n        Number of hidden features.\n    out_channels: int, (default=1)\n        Number of output channels.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        hid_channels: int = 128,\n        hid_features: int = 1024,\n        out_features: int = 1,\n        n_tracks: int = 4,\n        n_bars: int = 2,\n        n_steps_per_bar: int = 16,\n        n_pitches: int = 84,\n    ) -> None:\n        \"\"\"Initialize.\"\"\"\n        super().__init__()\n        self.n_tracks = n_tracks\n        self.n_bars = n_bars\n        self.n_steps_per_bar = n_steps_per_bar\n        self.n_pitches = n_pitches\n        in_features = 4 * hid_channels if n_bars == 2 else 12 * hid_channels\n        self.net = nn.Sequential(\n            # input shape: (batch_size, n_tracks, n_bars, n_steps_per_bar, n_pitches)\n            nn.Conv3d(self.n_tracks, hid_channels, (2, 1, 1), (1, 1, 1), padding=0),\n            nn.LeakyReLU(0.3, inplace=True),\n            # output shape: (batch_size, hid_channels, n_bars//2, n_steps_per_bar, n_pitches)\n            nn.Conv3d(hid_channels, hid_channels, (self.n_bars - 1, 1, 1), (1, 1, 1), padding=0),\n            nn.LeakyReLU(0.3, inplace=True),\n            # output shape: (batch_size, hid_channels, n_bars//2, n_steps_per_bar, n_pitches)\n            nn.Conv3d(hid_channels, hid_channels, (1, 1, 12), (1, 1, 12), padding=0),\n            nn.LeakyReLU(0.3, inplace=True),\n            # output shape: (batch_size, hid_channels, n_bars//2, n_steps_per_bar, n_pitches//12)\n            nn.Conv3d(hid_channels, hid_channels, (1, 1, 7), (1, 1, 7), padding=0),\n            nn.LeakyReLU(0.3, inplace=True),\n            # output shape: (batch_size, hid_channels, n_bars//2, n_steps_per_bar//2, n_pitches//12)\n            nn.Conv3d(hid_channels, hid_channels, (1, 2, 1), (1, 2, 1), padding=0),\n            nn.LeakyReLU(0.3, inplace=True),\n            # output shape: (batch_size, hid_channels, n_bars//2, n_steps_per_bar//4, n_pitches//12)\n            nn.Conv3d(hid_channels, hid_channels, (1, 2, 1), (1, 2, 1), padding=0),\n            nn.LeakyReLU(0.3, inplace=True),\n            # output shape: (batch_size, hid_channels, n_bars//2, n_steps_per_bar//4, n_pitches//12)\n            nn.Conv3d(hid_channels, 2 * hid_channels, (1, 4, 1), (1, 2, 1), padding=(0, 1, 0)),\n            nn.LeakyReLU(0.3, inplace=True),\n            # output shape: (batch_size, hid_channels, n_bars//2, n_steps_per_bar//8, n_pitches//12)\n            nn.Conv3d(2 * hid_channels, 4 * hid_channels, (1, 3, 1), (1, 2, 1), padding=(0, 1, 0)),\n            nn.LeakyReLU(0.3, inplace=True),\n            # output shape: (batch_size, hid_channels, n_bars//2, n_steps_per_bar//16, n_pitches//12)\n            nn.Flatten(),\n            nn.Linear(in_features, hid_features),\n            nn.LeakyReLU(0.3, inplace=True),\n            # output shape: (batch_size, hid_features)\n            nn.Linear(hid_features, out_features),\n            # output shape: (batch_size, out_features)\n        )\n\n    def forward(self, x: Tensor) -> Tensor:\n        \"\"\"Perform forward.\n\n        Parameters\n        ----------\n        x: Tensor\n            Input batch.\n\n        Returns\n        -------\n        Tensor:\n            Preprocessed input batch.\n\n        \"\"\"\n        fx = self.net(x)\n        return fx\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-18T11:17:18.183491Z","iopub.execute_input":"2022-09-18T11:17:18.183948Z","iopub.status.idle":"2022-09-18T11:17:18.198580Z","shell.execute_reply.started":"2022-09-18T11:17:18.183899Z","shell.execute_reply":"2022-09-18T11:17:18.197501Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import logging\nimport os\nimport torch\nimport torchvision.models\nfrom torch import nn\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\nimport logging\nimport os\nimport torch\nimport torchvision.models\nfrom torch import nn\nclass MuseGan(nn.Module):\n    def __init__(self, experiment_dir=\"base_muse_gan\",\n                 reset=False, load_best=True):\n        super(MuseGan, self).__init__()\n        self.experiment_dir = experiment_dir\n        self.model_name = os.path.basename(self.experiment_dir)\n        self.reset = reset\n        self.load_best = load_best\n        self.setup_dirs()\n\n\n\n\n\n        self.setup_network()\n\n        if not reset: self.load_state()\n\n    ##1. Defining network architecture\n    def setup_network(self):\n        \"\"\"\n        Initialize the network  architecture here\n        @return:\n        \"\"\"\n\n        #1: load model config\n        config_file=os.path.join(self.experiment_dir,\"config.json\")\n        assert os.path.exists(config_file),f\"No config.json found in {self.experiment_dir}\"\n        model_config=read_json(config_file)\n        self.z_dimension =model_config[\"z_dimension\"]\n        self.g_channels =model_config[\"g_channels\"]\n        self.g_features =model_config[\"g_features\"]\n        self.c_channels =model_config[\"c_channels\"]\n        self.c_features = model_config[\"c_features\"]\n        self.n_bars=model_config[\"n_bars\"]\n        self.step_bars=model_config[\"step_bars\"]\n        self.n_pitches=model_config[\"n_pitches\"]\n        self.n_tracks=model_config[\"n_tracks\"]\n\n\n        self.generator = MuseGenerator(\n            z_dimension=self.z_dimension,\n            hid_channels=self.g_channels,\n            hid_features=self.g_features,\n            out_channels=1,\n            n_tracks=self.n_tracks,\n            n_pitches=self.n_pitches,\n            n_bars=self.n_bars,\n            n_steps_per_bar=self.step_bars\n        ).to(DEVICE)\n        self.generator=self.generator.apply(initialize_weights)\n\n\n        self.critic=MuseCritic(\n            hid_channels=self.c_channels,\n            hid_features=self.c_features,\n            out_features=1,\n            n_tracks=self.n_tracks,\n            n_bars=self.n_bars,\n            n_steps_per_bar=self.step_bars,\n            n_pitches=self.n_pitches\n            )\n        self.critic=self.critic.apply(initialize_weights)\n\n\n    ##2. Model Saving/Loading\n    def load_state(self, best=False):\n        \"\"\"\n        Load model\n        :param self:\n        :return:\n        \"\"\"\n        if best and os.path.exists(self.save_best_file):\n            logging.info(f\"Loading best model state : {self.save_file}\")\n            self.load_state_dict(torch.load(self.save_file, map_location=DEVICE))\n            return\n\n        if os.path.exists(self.save_file):\n            logging.info(f\"Loading model state : {self.save_file}\")\n            self.load_state_dict(torch.load(self.save_file, map_location=DEVICE))\n\n    def save_state(self, best=False):\n        if best:\n            logging.info(\"Saving best model\")\n            torch.save(self.state_dict(), self.save_best_file)\n        torch.save(self.state_dict(), self.save_file)\n\n    ##3. Setupping directories for weights /logs ... etc\n    def setup_dirs(self):\n        \"\"\"\n        Checking and creating directories for weights storage\n        @return:\n        \"\"\"\n        self.save_file = os.path.join(self.experiment_dir, f\"{self.model_name}.pt\")\n        self.save_best_file = os.path.join(self.experiment_dir, f\"{self.model_name}_best.pt\")\n        if not os.path.exists(self.experiment_dir):\n            os.makedirs(self.experiment_dir)\n\n\n\n\n\n\n\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-18T11:17:18.202330Z","iopub.execute_input":"2022-09-18T11:17:18.202726Z","iopub.status.idle":"2022-09-18T11:17:18.424175Z","shell.execute_reply.started":"2022-09-18T11:17:18.202689Z","shell.execute_reply":"2022-09-18T11:17:18.423221Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"\"\"\"Midi dataset.\"\"\"\nfrom typing import Tuple\nfrom torch import Tensor\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset\nimport numpy as np\nfrom music21 import midi\nfrom music21 import converter\nfrom music21 import note, stream, duration, tempo\nclass LPDDataset(Dataset):\n    \"\"\"LPDDataset.\n\n    Parameters\n    ----------\n    path: str\n        Path to dataset.\n    \"\"\"\n\n    def __init__(\n        self,\n        path: str,\n    ) -> None:\n        \"\"\"Initialize.\"\"\"\n        dataset = np.load(path, allow_pickle=True, encoding=\"bytes\")\n        self.data_binary = dataset[\"arr_0\"]\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of samples in dataset.\"\"\"\n        return len(self.data_binary)\n\n    def __getitem__(self, index: int) -> Tensor:\n        \"\"\"Return one samples from dataset.\n\n        Parameters\n        ----------\n        index: int\n            Index of sample.\n\n        Returns\n        -------\n        Tensor:\n            Sample.\n\n        \"\"\"\n        return torch.from_numpy(self.data_binary[index]).float()\n\nclass MidiDataset(Dataset):\n    \"\"\"MidiDataset.\n\n    Parameters\n    ----------\n    path: str\n        Path to dataset.\n    split: str, optional (default=\"train\")\n        Split of dataset.\n    n_bars: int, optional (default=2)\n        Number of bars.\n    n_steps_per_bar: int, optional (default=16)\n        Number of steps per bar.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        path: str,\n        # split: str = \"train\",\n        split: str = \"train\",\n        n_bars: int = 2,\n        n_steps_per_bar: int = 16,\n    ) -> None:\n        \"\"\"Initialize.\"\"\"\n        self.n_bars = n_bars\n        self.n_steps_per_bar = n_steps_per_bar\n        dataset = np.load(path, allow_pickle=True, encoding=\"bytes\")[split]\n        self.data_binary, self.data_ints, self.data = self.__preprocess__(dataset)\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of samples in dataset.\"\"\"\n        return len(self.data_binary)\n\n    def __getitem__(self, index: int) -> Tensor:\n        \"\"\"Return one samples from dataset.\n\n        Parameters\n        ----------\n        index: int\n            Index of sample.\n\n        Returns\n        -------\n        Tensor:\n            Sample.\n\n        \"\"\"\n        return torch.from_numpy(self.data_binary[index]).float()\n\n    def __preprocess__(self, data: np.ndarray) -> Tuple[np.ndarray]:\n        \"\"\"Preprocess data.\n\n        Parameters\n        ----------\n        data: np.ndarray\n            Data.\n\n        Returns\n        -------\n        Tuple[np.ndarray]:\n            Data binary, data ints, preprocessed data.\n\n        \"\"\"\n        data_ints = []\n        for x in data:\n            skip = True\n            skip_rows = 0\n            while skip:\n                if not np.any(np.isnan(x[skip_rows: skip_rows + 4])):\n                    skip = False\n                else:\n                    skip_rows += 4\n            if self.n_bars * self.n_steps_per_bar < x.shape[0]:\n                data_ints.append(x[skip_rows: self.n_bars * self.n_steps_per_bar + skip_rows, :])\n        data_ints = np.array(data_ints)\n        self.n_songs = data_ints.shape[0]\n        self.n_tracks = data_ints.shape[2]\n        data_ints = data_ints.reshape([self.n_songs, self.n_bars, self.n_steps_per_bar, self.n_tracks])\n        max_note = 83\n        mask = np.isnan(data_ints)\n        data_ints[mask] = max_note + 1\n        max_note = max_note + 1\n        data_ints = data_ints.astype(int)\n        num_classes = max_note + 1\n        data_binary = np.eye(num_classes)[data_ints]\n        data_binary[data_binary == 0] = -1\n        data_binary = np.delete(data_binary, max_note, -1)\n        data_binary = data_binary.transpose([0, 3, 1, 2, 4])\n        return data_binary, data_ints, data\n\n\ndef binarise_output(output: np.ndarray) -> np.ndarray:\n    \"\"\"Binarize output.\n\n    Parameters\n    ----------\n    output: np.ndarray\n        Output array.\n\n    \"\"\"\n    max_pitches = np.argmax(output, axis=-1)\n    return max_pitches\n\n\ndef postprocess(\n    output: np.ndarray,\n    n_tracks: int = 4,\n    n_bars: int = 2,\n    n_steps_per_bar: int = 16,\n) -> stream.Score:\n    \"\"\"Postprocess output.\n\n    Parameters\n    ----------\n    output: np.ndarray\n        Output array.\n    n_tracks: int, (default=4)\n        Number of tracks.\n    n_bars: int, (default=2)\n        Number of bars.\n    n_steps_per_bar: int, (default=16)\n        Number of steps per bar.\n\n    \"\"\"\n    parts = stream.Score()\n    parts.append(tempo.MetronomeMark(number=66))\n    max_pitches = binarise_output(output)\n    midi_note_score = np.vstack([\n        max_pitches[i].reshape([n_bars * n_steps_per_bar, n_tracks]) for i in range(len(output))\n    ])\n    for i in range(n_tracks):\n        last_x = int(midi_note_score[:, i][0])\n        s = stream.Part()\n        dur = 0\n        for idx, x in enumerate(midi_note_score[:, i]):\n            x = int(x)\n            if (x != last_x or idx % 4 == 0) and idx > 0:\n                n = note.Note(last_x)\n                n.duration = duration.Duration(dur)\n                s.append(n)\n                dur = 0\n            last_x = x\n            dur = dur + 0.25\n        n = note.Note(last_x)\n        n.duration = duration.Duration(dur)\n        s.append(n)\n        parts.append(s)\n    return parts\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-18T11:17:18.425682Z","iopub.execute_input":"2022-09-18T11:17:18.426043Z","iopub.status.idle":"2022-09-18T11:17:18.600890Z","shell.execute_reply.started":"2022-09-18T11:17:18.426004Z","shell.execute_reply":"2022-09-18T11:17:18.599978Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Loss and metrics","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"\nfrom torch import Tensor\n\nimport torch\nfrom torch import nn\n\n\nclass WassersteinLoss(nn.Module):\n    \"\"\"WassersteinLoss.\"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Initialize.\"\"\"\n        super().__init__()\n\n    def forward(self, y_pred: Tensor, y_target: Tensor) -> Tensor:\n        \"\"\"Calculate Wasserstein loss.\n\n        Parameters\n        ----------\n        y_pred: Tensor\n            Prediction.\n        y_target: Tensor\n            Target.\n\n        Returns\n        -------\n        Tensor:\n            Loss value.\n\n        \"\"\"\n        loss = - torch.mean(y_pred * y_target)\n        return loss\n\nclass GradientPenalty(nn.Module):\n    \"\"\"Gradient penalty.\"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Initialize.\"\"\"\n        super().__init__()\n\n    def forward(self, inputs: Tensor, outputs: Tensor) -> Tensor:\n        \"\"\"Calculate gradient penalty.\n\n        Parameters\n        ----------\n        inputs: Tensor\n            Input from which to track gradient.\n        outputs: Tensor\n            Output to which to track gradient.\n\n        Returns\n        -------\n        Tensor:\n            Penalty value.\n\n        \"\"\"\n        grad = torch.autograd.grad(\n            inputs=inputs,\n            outputs=outputs,\n            grad_outputs=torch.ones_like(outputs),\n            create_graph=True,\n            retain_graph=True,\n        )[0]\n        grad_ = torch.norm(grad.view(grad.size(0), -1), p=2, dim=1)\n        penalty = torch.mean((1. - grad_) ** 2)\n        return penalty\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-18T11:17:18.602119Z","iopub.execute_input":"2022-09-18T11:17:18.603058Z","iopub.status.idle":"2022-09-18T11:17:18.611741Z","shell.execute_reply.started":"2022-09-18T11:17:18.603029Z","shell.execute_reply":"2022-09-18T11:17:18.610419Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Trainer","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"import csv\nimport json\nimport logging\nimport os\nimport shutil\n\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.tensorboard import SummaryWriter\nfrom tqdm import tqdm\n\nclass Trainer:\n    \"\"\"\n    Class to manage the full training pipeline\n    \"\"\"\n    def __init__(self, network:MuseGan,\n                 g_optimizer,\n                 c_optimizer,\n                 nb_epochs=10,\n                 repeat=5,\n                 batch_size=128,\n                 reset=False):\n        \"\"\"\n        @param network:\n        @param dataset_name:\n        @param images_dirs:\n        @param loss:\n        @param optimizer:\n        @param nb_epochs:\n        @param nb_workers: Number of worker for the dataloader\n        \"\"\"\n        self.network = network\n        self.batch_size = batch_size\n        self.repeat=repeat\n        self.g_optimizer=g_optimizer\n        self.c_optimizer = c_optimizer\n        \n        self.g_criterion = WassersteinLoss().to(DEVICE)\n        self.c_criterion = WassersteinLoss().to(DEVICE)\n        \n        \n        self.c_penalty=GradientPenalty().to(DEVICE)\n        \n        self.nb_epochs = nb_epochs\n        self.experiment_dir = self.network.experiment_dir\n        self.model_info_file = os.path.join(self.experiment_dir, \"model.json\")\n        self.model_info_best_file = os.path.join(self.experiment_dir, \"model_best.json\")\n\n        if reset:\n            if os.path.exists(self.experiment_dir):\n                shutil.rmtree(self.experiment_dir)\n        if not os.path.exists(self.experiment_dir):\n            os.makedirs(self.experiment_dir)\n\n        self.start_epoch = 0\n        if not reset and os.path.exists(self.model_info_file):\n            with open(self.model_info_file, \"r\") as f:\n                self.start_epoch = json.load(f)[\"epoch\"] + 1\n                self.nb_epochs += self.start_epoch\n                logging.info(\"Resuming from epoch {}\".format(self.start_epoch))\n\n\n    def save_model_info(self, infos, best=False):\n        json.dump(infos, open(self.model_info_file, 'w'),indent=4)\n        if best: json.dump(infos, open(self.model_info_best_file, 'w'),indent=4)\n\n    def fit(self,train_dataloader):\n        logging.info(\"Launch training on {}\".format(DEVICE))\n        self.network.train()\n        self.network.to(DEVICE)\n        self.summary_writer = SummaryWriter(log_dir=self.experiment_dir)\n        itr = self.start_epoch * len(train_dataloader) * self.batch_size  ##Global counter for steps\n        if os.path.exists(self.model_info_file):\n            with open(self.model_info_file, \"r\") as f:\n                model_info = json.load(f)\n                lr=model_info[\"lr\"]\n                logging.info(f\"Setting lr to {lr}\")\n                for g in self.optimizer.param_groups:\n                    g['lr'] = lr\n        if os.path.exists(self.model_info_best_file):\n            with open(self.model_info_best_file, \"r\") as f:\n                best_model_info = json.load(f)\n                best_loss = best_model_info[\"val_loss\"]\n\n        self.alpha = torch.rand((self.batch_size, 1, 1, 1, 1)).requires_grad_().to(DEVICE)\n        for epoch in range(self.start_epoch, self.nb_epochs):  # Training loop\n            epoch_gloss = Averager()\n            epoch_cfloss = Averager()\n            epoch_crloss = Averager()\n            epoch_cploss = Averager()\n            epoch_closs = Averager()\n            pbar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{self.nb_epochs}\")\n            for _, real in enumerate(pbar):\n                \"\"\"\n                Training lopp\n                \"\"\"\n                itr+=1\n                #Train the critic\n                real=real.to(DEVICE)\n                batch_closs = Averager()\n                batch_cfloss = Averager()\n                batch_crloss = Averager()\n                batch_cploss = Averager()\n                for _ in range(self.repeat):\n                    cords = torch.randn(self.batch_size, 32).to(DEVICE)\n                    style = torch.randn(self.batch_size, 32).to(DEVICE)\n                    melody = torch.randn(self.batch_size, 4, 32).to(DEVICE)\n                    groove = torch.randn(self.batch_size, 4, 32).to(DEVICE)\n\n                    self.c_optimizer.zero_grad()\n                    with torch.no_grad():\n                        fake = self.network.generator(cords, style, melody, groove).detach()\n                    realfake = self.alpha * real + (1. - self.alpha) * fake\n\n                    fake_pred = self.network.critic(fake)\n                    real_pred = self.network.critic(real)\n                    realfake_pred = self.network.critic(realfake)\n                    fake_loss = self.c_criterion(fake_pred, - torch.ones_like(fake_pred))\n                    real_loss = self.c_criterion(real_pred, torch.ones_like(real_pred))\n                    penalty = self.c_penalty(realfake, realfake_pred)\n                    closs = fake_loss + real_loss + 10 * penalty\n                    closs.backward(retain_graph=True)\n                    self.c_optimizer.step()\n                    batch_cfloss.send(fake_loss.item())\n                    batch_crloss.send(real_loss.item())\n                    batch_cploss.send(10 * penalty.item())\n                    batch_closs.send(closs.item() / self.repeat)\n\n\n                # Train Generator\n                self.g_optimizer.zero_grad()\n                cords = torch.randn(self.batch_size, 32).to(DEVICE)\n                style = torch.randn(self.batch_size, 32).to(DEVICE)\n                melody = torch.randn(self.batch_size, 4, 32).to(DEVICE)\n                groove = torch.randn(self.batch_size, 4, 32).to(DEVICE)\n\n                fake = self.network.generator(cords, style, melody, groove)\n                fake_pred = self.network.critic(fake)\n                b_gloss = self.g_criterion(fake_pred, torch.ones_like(fake_pred))\n                b_gloss.backward()\n                self.g_optimizer.step()\n\n                \"\"\"\n                4.Writing logs and tensorboard data, loss and other metrics\n                \"\"\"\n                batch_data={\n                \"generator_loss\":b_gloss.item(),\n                \"critic_loss\":batch_closs.value,\n                \"critic_fake_loss\":batch_cfloss.value,\n                \"critic_real_loss\":batch_crloss.value,\n                \"critic_penalized_loss\":batch_cploss.value\n                    }\n\n                for k,v in batch_data.items():\n                    self.summary_writer.add_scalar(f\"Train steps/{k}\", v, itr)\n\n                epoch_gloss.send(b_gloss.item())\n                epoch_cfloss.send(batch_cfloss.value)\n                epoch_crloss.send(batch_crloss.value)\n                epoch_cploss.send(batch_cploss.value)\n                epoch_closs.send(batch_closs.value)\n\n\n            epoch_data={\n                \"generator_loss\":epoch_gloss.value,\n                \"critic_loss\":epoch_closs.value,\n                \"critic_fake_loss\":epoch_cfloss.value,\n                \"critic_real_loss\":epoch_crloss.value,\n                \"critic_penalized_loss\":epoch_cploss.value\n            }\n            for k,v in epoch_data.items():\n                self.summary_writer.add_scalar(f\"Train epochs/{k}\",v,epoch)\n            logging.info(f\"Epoch {epoch}/{self.nb_epochs} | Generator loss: {epoch_gloss.value:.3f} | Critic loss: {epoch_closs.value:.3f}\")\n            logging.info(f\"Critic performance (fake: {epoch_cfloss.value:.3f}, real: {epoch_crloss.value:.3f}, penalty: {epoch_cploss.value:.3f})\")\n\n            #TODO write epoch metrics results\n            infos = epoch_data\n            infos[\"epoch\"]=epoch\n            infos[\"batch_size\"]=self.batch_size\n            infos[\"generator_lr\"]=self.g_optimizer.param_groups[0]['lr']\n            infos[\"critic_lr\"] = self.c_optimizer.param_groups[0]['lr']\n            self.network.save_state()\n            self.save_model_info(infos)\n            ","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-18T11:17:18.613204Z","iopub.execute_input":"2022-09-18T11:17:18.613747Z","iopub.status.idle":"2022-09-18T11:17:19.071116Z","shell.execute_reply.started":"2022-09-18T11:17:18.613713Z","shell.execute_reply":"2022-09-18T11:17:19.070146Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Launch Training","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"from collections import namedtuple\nimport argparse\nimport json\nimport logging\nimport os\nimport torch.utils.data\nfrom torch.optim import Adam\n\ndef main(args):\n    model_name = \"base_model\" if args.model_name is None else args.model_name\n    experiment_dir = os.path.join(EXPERIMENTS_DIR, model_name)\n    config_file=os.path.join(experiment_dir,\"config.json\")\n\n    if not os.path.exists(experiment_dir):os.makedirs(experiment_dir)\n    if  not os.path.exists(config_file) or args.reset:\n        model_config={\n        \"z_dimension\":args.z_dimension,\n        \"g_channels\": args.g_channels,\n        \"g_features\" : args.g_features,\n        \"c_channels\" : args.c_channels,\n        \"c_features\" : args.c_features,\n        \"n_bars\":args.n_bars,\n        \"step_bars\":args.step_bars,\n        \"n_tracks\":args.n_tracks,\n        \"n_pitches\":args.n_pitches\n        }\n        with open(config_file,\"w\") as f:json.dump(model_config,f,indent=4)\n\n\n\n    network=MuseGan(experiment_dir=experiment_dir,\n                    reset=args.reset,\n\n                    )\n\n\n    g_optimizer = Adam(network.generator.parameters(),lr=args.g_lr,betas=(0.5, 0.9))\n    c_optimizer = Adam(network.critic.parameters(),lr=args.c_lr,betas=(0.5, 0.9))\n\n    logging.info(\"Training : \"+model_name)\n    trainer = Trainer(network,\n                      g_optimizer,\n                      c_optimizer,\n                      nb_epochs= args.nb_epochs,\n                      batch_size=args.batch_size,\n                      reset=args.reset,\n                      )\n\n    train_dataset=LPDDataset(DATASET_FILE)\n    train_dataloader=torch.utils.data.DataLoader(train_dataset,batch_size=args.batch_size,num_workers=args.num_workers,shuffle=True,drop_last=True)\n    trainer.fit(train_dataloader)\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-18T11:17:19.073143Z","iopub.execute_input":"2022-09-18T11:17:19.073495Z","iopub.status.idle":"2022-09-18T11:17:19.086225Z","shell.execute_reply.started":"2022-09-18T11:17:19.073461Z","shell.execute_reply":"2022-09-18T11:17:19.085220Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"args={\n        \"reset\":False,\n        \"learning_rate\":0.001,\n        \"nb_epochs\":20,\n        \"model_name\":\"base_muse_gan\",\n        \"num_workers\":0,\n        \"batch_size\":128,\n        \"z_dimension\":32,\n        \"g_channels\":1024,\n        \"g_features\":1024,\n        \"g_lr\":0.001,\n        \"c_channels\":128,\n        \"c_features\":1024,\n        \"c_lr\":0.001,\n        \"n_bars\":5,\n        \"step_bars\":48,\n        \"n_tracks\":4,\n        \"n_pitches\":84,\n        \"log_level\":\"INFO\"\n        }\nargs=namedtuple(\"args\",args.keys())(*args.values())\nmain(args)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-18T11:17:19.088128Z","iopub.execute_input":"2022-09-18T11:17:19.088397Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Epoch 1/20:   2%|▏         | 12/799 [01:45<1:44:49,  7.99s/it]","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]}]}